<!DOCTYPE HTML>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Hi, Hardik Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-CY1Z17Q8ZG"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-CY1Z17Q8ZG');
    </script>


    <title>Hardik Shah</title>
    
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

    <meta name="author" content="Hardik Shah">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="Description" content="Hardik Shah | ETH Zurich | Google | BITS Goa">
    <meta name="keywords" content="Hardik Shah, ETH, Zurich, CVG, RPG, Computer Vision, Scandit, Google, CEERI, CSIR, Deep Learning, SAiDL, APPCAIR, BITS Goa, Artificial Intelligence, Project Kratos, Autonomous Subsystem">

    <!-- <link rel="stylesheet" type="text/css" href="stylesheet.css"> -->
    <link rel="icon" type="image/png" href="images/HS.png" >
</head>
<body class="bg_colour">
    <table border=0 class="bg_colour" style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
            <td style="padding:0px">
                
                <!-- Name tab -->
                <table border=0 class="bg_colour" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    
                    
                    <tr style="padding:0px">
                        <td style="padding:2.5%;width:25%;max-width:60%">
                            <a href="images/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpg" class="img-circle"></a>
                        </td>
                        <td style="padding:2.5%;width:60%;vertical-align:middle">
                            <p style="text-align:center">
                                <h1  style="text-align:center"><name>Hardik Shah</name></h1>
                            </p>

                            <p>
                                I am a Computer Science MSc student at ETH Zurich, majoring in Machine Intelligence, with a focus on Computer Vision and Mobile Robotics. I did my
                                bachelors in Computer Science (w/ minor in Data Science) from <a href="https://www.bits-pilani.ac.in/goa/" target="_blank">BITS Pilani, Goa</a>. I am 
                                currently working as a Computer Vision Intern at <a href="https://www.scandit.com/" target="_blank">Scandit</a>, solving interest point detection and tracking
                                in the <a href="https://www.scandit.com/products/matrixscan/" target="_blank">MatrixScan</a> pipeline.
                            </p>
                            <!-- <p>
                                I wish to explore robotic visual perception and its applications in autonomous driving, intelligent reasoning, and scene understanding. After exploring a 
                                breadth of vision-based research problem statements from dense reconstruction to depth estimation and optical character recognition, I find myself at the 
                                minima of the Dunning Kruger curve. I am particularly curious about classical computer vision techniques and visual odometry pipelines, and how they can be 
                                leveraged to make end-to-end deep learning pipelines tractable and resource constrained.                  
                            </p> -->
                            <p>
                                <!-- TODO: add subpoints for each, remove APPCAIR -->
                                I have had the pleasure of working on the following projects with some amazing researchers and engineers at:<br>
                                <ul>
                                    <li> <a href="https://www.scandit.com/" target="_blank">Scandit</a></li>
                                    <ul>
                                        <li>Lightweight Learned Detection and Matching for <a href="https://www.scandit.com/products/matrixscan/" target="_blank">MatrixScan</a></li>
                                    </ul>
                                    <br>
                                    <li> <a href="https://rpg.ifi.uzh.ch/" target="_blank"> Robotics and Perception Group (RPG)</a>, UZH with <a href="https://rpg.ifi.uzh.ch/people_scaramuzza.html" target="_blank">Prof. Davide Scaramuzza</a> </li>
                                    <ul>
                                        <li>Object Goal Navigation using Vision Foundation Models</li>
                                    </ul>
                                    <br>
                                    <li> <a href="https://cvg.ethz.ch/" target="_blank"> Computer Vision and Geometry Group (CVG)</a>, ETH with <a href="https://cvg.ethz.ch/team/Prof-Dr-Marc-Pollefeys" target="_blank">Prof. Marc Pollefeys</a> </li>
                                    <ul>
                                        <li>Joint Detection of Point and Line Features for faster and robust SLAM</li>
                                    </ul>
                                    <br>
                                    <li> <a href="https://research.google/teams/india-research-lab/" target="_blank"> Google Research</a> with <a href="https://www.prateekjain.org/" target="_blank">Dr. Prateek Jain</a></li>
                                    <ul>
                                        <li>Undergraduate Thesis. 
                                            Accepted to <a href="https://openaccess.thecvf.com/content/CVPR2024W/MAI/papers/Nasery_End-to-End_Neural_Network_Compression_via_l1l2_Regularized_Latency_Surrogates_CVPRW_2024_paper.pdf" target="_blank"><b>CVPRW '24</b></a>.
                                        </li>
                                    </ul>
                                    <br>
                                    <li> <a href="https://www.hka.uka.de/" target="_blank"> Robot Vision Lab</a>, Karlsruhe, Germany (HKA) with <a href="https://www.niclas-zeller.de/" target="_blank">Prof. Dr. Niclas Zeller</a></li>
                                    <ul>
                                        <li>Dense 3D Reconstruction Toolkit. 
                                            [<a href="https://github.com/hardik01shah/DenseReconstructionTools" target="_blank"><b>Code</b></a>][<a href="https://hardik01shah.github.io/DenseReconstructionTools/" target="_blank"><b>Website</b></a>]
                                        </li>
                                    </ul>
                                    <!-- <li> <a href="https://www.ceeri.res.in/" target="_blank"> Central Electronics Engineering Research Institute(CEERI)</a> with <a href="https://www.bits-pilani.ac.in/pilani/sandeepjoshi/profile" target="_blank">Prof. Sandeep Joshi</a></li> -->
                                    <!-- <li> <a href="https://www.bits-pilani.ac.in/appcair/" target="_blank"> APPCAIR</a> with <a href="https://www.bits-pilani.ac.in/goa/dandas/profile" target="_blank">Prof. Sravan Danda</a> and <a href="https://www.bits-pilani.ac.in/goa/adityac/profile" target="_blank">Prof. Aditya Challa</a></li> -->
                                    <br>
                                    <li> <a href="https://kratos-the-rover.github.io/" target="_blank"> Project Kratos</a> as the Autonomous Subsystem Lead (2021-22)</li>
                                    <ul>
                                        <li>We finished 2nd in Asia and 20th in the world among 99 teams at the <a href="https://urc.marssociety.org/" target="_blank"> University Rover Challenge (URC) 2022!</a></li>
                                    </ul>

                                </ul>
                            </p>
                            <!-- <p> -->
                                <!-- I finished my undergraduate thesis as a Student Researcher at the Machine Learning and Optimization Team, Google Research India. 
                                I was supervised by <a href="https://www.prateekjain.org/" target="_blank">Dr. Prateek Jain</a> and my work revolved around reducing the on-device
                                latency of large vision models for faster on-device inference. I spent my '22 summer in Karlsruhe, Germany at the Robot Vision Lab, HKA where I worked 
                                on dense 3D Reconstruction using an Intel RealSense Camera with <a href="https://www.niclas-zeller.de/" target="_blank">Dr. Niclas Zeller</a>.   -->
                            <!-- </p>
                            <p> -->
                                <!-- As an undergraduate student at BITS, I collaborated with <a href="https://www.bits-pilani.ac.in/goa/dandas/profile"  target="_blank">Prof. Sravan Danda</a> and
                                <a href="https://www.bits-pilani.ac.in/goa/adityac/profile"  target="_blank">Prof. Aditya Challa</a> on Sparse Depth completion using RGB guidance. 
                                Previously, I've worked with <a href="https://www.bits-pilani.ac.in/goa/rakeshw/profile"  target="_blank">Prof. Rakesh Warier</a> on integration of 
                                the Unity Game Engine and ROS for simulation of differential drive robots. I also spent the summer as a Machine Learning Research Intern at 
                                <a href="https://www.ceeri.res.in/"  target="_blank">CEERI</a> where I worked with PPG signals for classification of human subjects as fatigued or non-fatigued. -->
                            <!-- </p>
                            <p> -->
                                <!-- I was involved in various student projects at BITS Pilani, Goa including <a href="https://kratos-the-rover.github.io/"  target="_blank">Project Kratos</a> where I
                                 led the Autonomous Subsystem of a Mars Rover prototype, and <a href="https://www.saidl.in/"  target="_blank">Society for AI and Deep Learning</a>.
                            </p> -->
                            
                            
                            <!-- <p style="text-align:center">
                            &nbsp|&nbsp
                            <a href="#news" onclick=Expand("news")>News</a>
                            &nbsp|&nbsp
                            <a href="#experience" onclick=Expand("experience")>Experience</a>
                            &nbsp|&nbsp
                            <a href="#publications" onclick=Expand("publications")>Publications</a>
                            &nbsp|&nbsp
                            <a href="#projects" onclick=Expand("projects")>Projects</a>
                            &nbsp|&nbsp
                            <a href="mailto:hardik01shah@gmail.com">Contact</a>
                            &nbsp|&nbsp
                            </p> -->
                        </td>
                        <!-- <td style="padding:2.5%;width:10%;max-width:10%"> -->
                            <!-- <a href="images/RishabKhinchaProfilePic.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/RishabKhinchaProfilePic.png" class="hoverZoomLink"></a> -->
                        <!-- </td> -->
                    </tr>
                    <!-- <tr>
                    <td colspan="2">
                        <p style="text-align:center">
                            &nbsp|&nbsp
                            <a href="#news" onclick=Expand("news")>News</a>
                            &nbsp|&nbsp
                            <a href="#experience" onclick=Expand("experience")>Experience</a>
                            &nbsp|&nbsp
                            <a href="#publications" onclick=Expand("publications")>Publications</a>
                            &nbsp|&nbsp
                            <a href="#projects" onclick=Expand("projects")>Projects</a>
                            &nbsp|&nbsp
                            <a href="#contact" onclick=Expand("contact")>Contact</a>
                            &nbsp|&nbsp
                        </p>
                    </td>
                    </tr> -->
                </tbody></table>


                <!-- About section, quick links -->

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr style="padding:0px">
                        <td style="padding:2.5%;width:63%;vertical-align:middle">
                            
                            <p>
                                I'm currently looking for full-time Machine Learning opportunities! I am excited about advancing research in foundation models and also their applications in robotics and perception systems.
                                Feel free to check out my 
                                <a href="data/HardikShahResume.pdf" target="_blank">Resume</a>
                                 and drop me an 
                                 <a href="mailto:hardik01shah@gmail.com" target="_blank">e-mail</a>
                                  if you want to chat with me! 
                            </p>
                            <br>
                            <p style="text-align:center">
                                &nbsp~&nbsp
                                <a href="mailto:hardik01shah@gmail.com" target="_blank">Email</a> &nbsp|&nbsp
                                <a href="data/HardikShahCV.pdf" target="_blank" >CV</a> &nbsp|&nbsp
                                <a href="data/HardikShahResume.pdf" target="_blank" >Resume</a> &nbsp|&nbsp
                                <!-- <a href="https://scholar.google.co.in/citations?user=PySXCeAAAAAJ&hl=en" target="_blank" >Google Scholar</a> &nbsp|&nbsp -->
                                <a href="https://github.com/hardik01shah" target="_blank" >Github</a> &nbsp|&nbsp
                                <a href="https://www.linkedin.com/in/hardik01shah" target="_blank">LinkedIn</a> 
                                <!-- <a href="https://twitter.com/hardik01shah" target="_blank">Twitter</a> -->
                                &nbsp~&nbsp
                            </p>
                            <br>
                            <p>
                                P.S. I play tennis, and find freedom in <a href="https://www.strava.com/athletes/70371331"  target="_blank">running and cycling</a>.
                                I also enjoy <a href="https://www.goodreads.com/user/show/100220306-hardik-shah"  target="_blank">reading</a> and occasionally dabble in <a href="https://www.chess.com/member/huntsman08" target="_blank">chess</a>.
                                Rafa remains the GOAT for me even if Djokovic goes on to win 30 grand slams.
                                
                                <!-- P.S. I like to believe I have a life outside of research and code :p. I like to read although I wish I had more time to indulge in <a href="https://www.goodreads.com/user/show/100220306-hardik-shah"  target="_blank">books</a>. 
                                I love <a href="https://www.strava.com/athletes/70371331"  target="_blank">sports</a> - anything. I have finished two half marathons, and a 25k trail run at Sethan Dome, India.
                                You might find me cycling to the university often. I play tennis, and Rafa remains the GOAT for me even if Djokovic goes on to win 30 gs.
                                And, I am up for a chess 10+0 or puzzle battle mostly all the time. -->
                            </p>
                        </td>
                        <!-- <td style="padding:2.5%;width:30%;max-width:30%">
                            <a href="images/RishabKhinchaProfilePic.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/RishabKhinchaProfilePic_round.png" class="hoverZoomLink"></a>
                        </td> -->
                    </tr>
                </tbody></table>
                <hr class="soft">

<!-- Experience -->

                <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-experience" id="experience"><heading>Experience</heading></button>
                <div id="content-experience" class="collapse in">

                <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    
                    <tr>
                        <td style="padding:25px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/scandit_logo.jpg' width="160">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Computer Vision Student Researcher</big> </papertitle> <papertitle><big> | Scandit</big></papertitle>
                            <br>
                            Jul '24 - Present
                            <br>
                            <i>ML in the Barcode Tracking Team</i> - With <a href="https://www.linkedin.com/in/menelaoskanakis/" target="_blank"><b>Menelaos Kanakis</b></a> and <a href="https://www.linkedin.com/in/matthias-bloch-b1663b255/" target="_blank"><b>Matthias Bloch</b></a>.
                            <br>
                            <br>
                            <p>
                                Replacing traditional keypoint detectors with <b>learned detection and matching methods</b> 
                                in the tracking pipeline of Scandit's <a href="https://www.scandit.com/products/matrixscan/" target="_blank">MatrixScan</a> product,
                                which leverages SLAM for AR-based inventory management on resource-constrained
                                devices. Optimizing training paradigms, and exploring lightweight architectures for
                                efficient on-device inference along with custom evaluation benchmarks.    
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:25px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/rpg_logo.png' width="160">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Graduate Student Researcher</big> </papertitle> <papertitle><big> | Robotics and Perception Group, UZH</big></papertitle>
                            <br>
                            Feb '24 - Present
                            <br>
                            <i>Research</i> - Under <a href="https://rpg.ifi.uzh.ch/" target="_blank"><b>Prof. Dr. Davide Scaramuzza</b></a>
                            <br>
                            <br>
                            <p>
                                Developed a <b>unified CLIP-based representation</b> combining 
                                geometry and semantics for <b>Object Goal Navigation</b> in unseen environments.
                                Demonstrated that integrating CLIP feature based representation along with frontier-based exploration outperforms recent segmentation-based methods, highlighting its robust generalization and zero-shot capabilities.
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:25px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/cvg_logo.png' width="120">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Graduate Student Researcher</big> </papertitle> <papertitle><big> | Computer Vision and Geometry Group, ETH</big></papertitle>
                            <br>
                            Feb '24 - Present
                            <br>
                            <i>Research</i> - Under <a href="https://cvg.ethz.ch/" target="_blank"><b>Prof. Dr. Marc Pollefeys</b></a>
                            <br>
                            <br>
                            <p>
                                Developed POLD2, a deep learning-based pipeline that jointly detects and describes
                                both <b>point and line features</b> in images, optimizing feature extraction for 3D vision
                                tasks like SLAM and pose estimation. By sharing computations between points and
                                lines, POLD2 achieves a significant 9.5x speedup in inference time compared to
                                traditional methods, while maintaining comparable accuracy.    
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/google_logo.png' width="120">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Student Researcher</big> </papertitle> <papertitle><big> | Google Research, India</big></papertitle>
                            <br>
                            Aug '22 - Jun '23
                            <br>
                            <i>Undergraduate Thesis</i> - Accepted to <a href="https://openaccess.thecvf.com/content/CVPR2024W/MAI/papers/Nasery_End-to-End_Neural_Network_Compression_via_l1l2_Regularized_Latency_Surrogates_CVPRW_2024_paper.pdf" target="_blank"><b>CVPRW '24</b></a>
                            <br>
                            <br>
                            <p>
                                Developed a versatile <b>neural network compression toolbox</b> that optimizes for the model's FLOPs via a novel
                                latency surrogate across a family of compression methods, including <b>pruning</b> and <b>low-rank factorization</b>. 
                                Additionally, optimized on-device latency of large vision models used for OCR tasks in <b>Google Lens</b>, and QR-code
                                scanning in <b>GooglePay</b>.
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/robot_vision_hka_logo.png' width="120">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Summer Research Intern</big> </papertitle> <papertitle><big> | Karlsruhe University of Applied Sciences, Germany</big></papertitle>
                            <br>
                            May '22 - Aug '22
                            <br>
                            <i>Research funded by the DAAD WISE Scholarship</i> [<a href="https://github.com/hardik01shah/DenseReconstructionTools" target="_blank"><b>Code</b></a>][<a href="https://hardik01shah.github.io/DenseReconstructionTools/" target="_blank"><b>Website</b></a>]
                            <br>
                            <p>
                                Designed an end to end pipeline for multi-view stereo dense 3D reconstruction from
                                a handheld stereo-camera(Intel RealSense) that outputs stable dense pointclouds. Integration of classical visual SLAM algorithms with U-Net adapted deep learning architectures for dense depth prediction.                             </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/BITSPilani_logo.png' width="120">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Researcher</big> </papertitle> <papertitle><big> | APPCAIR & Intel Labs</big></papertitle>
                            <br>
                            May '22 - Aug '22
                            <br>
                            <br>
                            <p>
                                Demonstrated use of ensemble learning for the task of activity recognition/video classifi-
                                cation on the Something-Something-v2 dataset. Weak learners were typically used
                                for feature extraction. Explored various methods for combination of features, ultimately
                                used for downstream classification
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/CEERI_logo.png' width="120">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Machine Learning Research Intern</big> </papertitle> <papertitle><big> | CEERI Pilani</big></papertitle>
                            <br>
                            May '21 - Sept '21
                            <br>
                            <br>
                            <p>
                                Worked under under the supervision of <a href="https://www.bits-pilani.ac.in/pilani/sandeepjoshi/profile"  target="_blank">Prof. Sandeep Joshi</a> 
                                and <a href="https://scholar.google.com/citations?user=_UXCzlMAAAAJ&hl=en"  target="_blank">Prof. Madan Lakshmanan</a>.
                                on classification of a person as fatigued or non-fatigued based on PPG signals of a human subject. 
                            </p>
                        </td>
                    </tr>

                </tbody></table>
                </div>
                <hr class="soft">
                
        <tr>
            <td>
                <p><em>
                    This template is a modification to Jon Barron's <a href="https://jonbarron.info/" target="_blank">website</a>. Last Updated: January 2025.
                </em>
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p></p>
            </td>
        </tr>
    </table>

</body>

</html>
